<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Codes</title>
<link rel="stylesheet" type="text/css" href="lzy.css">
</head>

<body>

<header>
<nav>
<ul>
    <li><a href="index.html">Home</a></li>
    <li><a href="publication.html">Publications</a></li>
    <li><a href="codes.html">Codes</a></li>
	<li><a href="index.html#Talks">Talks</a></li>
	<li><a href="index.html#Students">Students</a></li>
	<li><a href="index.html#Info">Info</a></li>
	<li><a href="index_cn.html">中文版</a></li>
</ul>
</nav>
<h1>Zhiyuan Liu</h1> 
</header>

<section>
The Tsinghua NLP (thunlp) Group devotes to make our NLP algorithms and methods available to everyone, which are expected to be used in Chinese NLP, Knowledge Graphs, and Social Computing. These codes are produced by members at thunlp Lab, headed by Prof. Maosong Sun and Associate Prof. Zhiyuan Liu.
</section>

<section>
<h2>Highlight Packages</h2>
<ul>
	<li> <strong>THULAC</strong>: An Efficient Lexical Analyzer for Chinese. [<a href=http://thulac.thunlp.org target=_blank>home</a>][<a href=https://github.com/thunlp/thulac target=_blank>Git C++</a>][<a href=https://github.com/thunlp/THULAC-Java target=_blank>Git Java</a>][<a href=https://github.com/thunlp/THULAC-Python target=_blank>Git Python</a>]

	<li> <strong>THUCTC</strong>: An Efficient Chinese Text Classifier. [<a HREF=http://thuctc.thunlp.org target=_blank>home</a>][<a HREF=https://github.com/thunlp/THUCTC target=_blank>Git Java</a>]

	<li> <strong>THUOCL</strong>: Open Chinese Lexicon. [<a HREF=http://thuocl.thunlp.org/target=_blank>home</a>]

	<li> <strong>OpenKE</strong>: An Open-Source Package for Knowledge Embedding (KE). [<a href=http://openke.thunlp.org target=_blank>home</a>][<a href=https://github.com/thunlp/OpenKE target=_blank>Git</a>] <br>

	<li> <strong>OpenNE</strong>: An Open-Source Package for Network Embedding (NE). [<a href=https://github.com/thunlp/OpenNE target=_blank>Git</a>] <br>
</ul>
</section>

<section>
<h2>Knowledge Graph and Relation Extraction</h2>
<ul>
	<li> <strong>NRE</strong>: An Open-Source Package for Neural Relation Extraction. [<a href=https://github.com/thunlp/NRE target=_blank>Git</a>][<a href=https://github.com/thunlp/TensorFlow-NRE target=_blank>TensorFlow Version</a>] <br>
	Neural relation extraction aims to extract relations from plain text with neural models, which has been the state-of-the-art methods for relation extraction. In this package, we provide our implementations of CNN [Zeng et al., 2014] and PCNN [Zeng et al.,2015] and their extended version with sentence-level attention scheme [Lin et al., 2016].

	<li> <strong>JointNRE</strong>: Joint Neural Relation Extraction with Text and KGs. [<a href=https://github.com/thunlp/JointNRE target=_blank>Git</a>] <br>
	This is the lab code of our AAAI 2018 paper "Neural Knowledge Acquisition via Mutual Attention between Knowledge Graph and Text".

	<li> <strong>PathNRE</strong>: Neural Relation Extraction with Relation Paths. [<a href=https://github.com/thunlp/PathNRE target=_blank>Git</a>] <br>
	This is the lab code of our EMNLP 2017 paper "Incorporating Relation Paths in Neural Relation Extraction".

	<li> <strong>Neural Entity Alignment</strong>. [<a href=https://github.com/thunlp/IEAJKE target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2017 paper "Iterative Entity Alignment via Joint Knowledge Embeddings".

	<li> <strong>Neural Entity Typing</strong>. [<a href=https://github.com/thunlp/KNET target=_blank>Git</a>] <br>
	This is the lab code of our AAAI 2018 paper "Improving Neural Fine-Grained Entity Typing with Knowledge Attention".
</ul>
</section>

<section>
<h2>Knowledge Representation Learning</h2>
<ul>
	<li> <strong>OpenKE</strong>: An Open-Source Package for Knowledge Embedding (KE). [<a href=https://github.com/thunlp/OpenKE target=_blank>Git</a>] <br>

	<li> <strong>KRLPapers</strong>: Must-read papers on knowledge representation learning (KRL) / knowledge embedding (KE). [<a href=https://github.com/thunlp/KRLPapers target=_blank>Git</a>] <br>

	<li> <strong>TransX</strong>: An Efficient implementation of TransE and its extended models for Knowledge Representation Learning. [<a href=https://github.com/thunlp/Fast-TransX target=_blank>Git</a>][<a href=https://github.com/thunlp/TensorFlow-TransX target=_blank>TensorFlow Version</a>] <br>

	<li> <strong>KB2E</strong>: A package of Knowledge Base to Embeddings. [<a href=https://github.com/thunlp/KB2E target=_blank>Git</a>] <br>
	The package contains state-of-the-art knowledge representation learning  methods including TransE, TransH, TransR and PTransE. 

	<li> <strong>KR-EAR</strong>: Knowledge Representation Learning with Entities, Attributes and Relations. [<a href=https://github.com/thunlp/KR-EAR target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2016 paper "Knowledge Representation Learning with Entities, Attributes and Relations".

	<li> <strong>CKRL</strong>: Confidence-aware Knowledge Representation Learning. [<a href=https://github.com/thunlp/CKRL target=_blank>Git</a>] <br>
	This is the lab code of our AAAI 2018 paper "Does William Shakespeare REALLY Write Hamlet? Knowledge Representation Learning with Confidence".  The method is expected to support robust knowledge representation learning with noisy triples. 

	<li> <strong>IKRL</strong>: Image-embodied Knowledge Representation Learning. [<a href=https://github.com/thunlp/IKRL target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2017 paper "Image-embodied Knowledge Representation Learning".  The method is expected to support knowledge representation learning with entity images. 

	<li> <strong>TKRL</strong>: Type-embodied Knowledge Representation Learning. [<a href=https://github.com/thunlp/TKRL target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2016 paper "Representation Learning of Knowledge Graphs with Hierarchical Types". The method is expected to support knowledge representation learning with hierarchical types of entities. 

	<li> <strong>DKRL</strong>: Description-embodied Knowledge Representation Learning. [<a href=https://github.com/thunlp/DKRL target=_blank>Git</a>] <br>
	This is the lab code of our AAAI 2016 paper "Representation Learning of Knowledge Graphs with Entity Descriptions". The method is expected to support knowledge representation learning with entity descriptions. 

</ul>
</section>

<section>
<h2>Network Representation Learning</h2>
<ul>
	<li> <strong>OpenNE</strong>: An Open-Source Package for Network Embedding (NE). [<a href=https://github.com/thunlp/OpenNE target=_blank>Git</a>] <br>

	<li> <strong>NRLPapers</strong>: Must-read papers on network representation learning (NRL) / network embedding (NE). [<a href=https://github.com/thunlp/NRLPapers target=_blank>Git</a>] <br>

	<li> <strong>TransNet</strong>: Translation-Based Network Representation Learning. [<a href=https://github.com/thunlp/TransNet target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2017 paper "TransNet: Translation-Based Network Representation Learning for Social Relation Extraction". The method is expected to model social networks by regarding relations as the translation between vertices.

	<li> <strong>NEU</strong>: Fast Network Embedding. [<a href=https://github.com/thunlp/NEU target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2017 paper "Fast Network Embedding Enhancement via High Order Proximity Approximation". The method is expected to speed up network embedding by approximate update algorithm.

	<li> <strong>CANE</strong>: Context-Aware Network Embedding. [<a href=https://github.com/thunlp/CANE target=_blank>Git</a>] <br>
	This is the lab code of our ACL 2017 paper "CANE: Context-Aware Network Embedding for Relation Modeling". The method is expected to support context-aware network representation learning and model asymmetric relations.

	<li> <strong>MMDW</strong>: Max-Margin DeepWalk. [<a href=https://github.com/thunlp/MMDW target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2016 paper "Max-Margin DeepWalk: Discriminative Learning of Network Representation". The method is expected to support discriminative network representation learning with node labels.

	<li> <strong>TADW</strong>: Text-Associated DeepWalk. [<a href=https://github.com/thunlp/TADW target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2015 paper "Network Representation Learning with Rich Text Information". The method is expected to support network representation learning with rich text information within each node. The code requires a 64-bit linux machine with MATLAB installed.
</ul>
</section>

<section>
<h2>Sememe-Driven NLP</h2>
<ul>
	<li> <strong>SE-WRL</strong>: Improved Word Representation Learning with Sememes. [<a href=https://github.com/thunlp/SE-WRL target=_blank>Git</a>] <br>
	This is the lab code of our ACL 2017 paper "Improved Word Representation Learning with Sememes". Sememes are minimum semantic units of word meanings, and the meaning of each word sense is typically composed by several sememes. We proposed the improved word representation learning method with sememe knowledge annotated in HowNet.

	<li> <strong>Lexical Sememe Prediction</strong>. [<a href=https://github.com/thunlp/sememe_prediction target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2017 paper "Lexical Sememe Prediction via Word Embeddings and Matrix Factorization".

	<li> <strong>Chinese LIWC Lexicon Expansion</strong>: Online Interpretable Word Embeddings. [<a href=https://github.com/thunlp/Auto_CLIWC target=_blank>Git</a>] <br>
	This is the lab code of our AAAI 2018 paper "Chinese LIWC Lexicon Expansion via Hierarchical Classification of Word Embeddings with Sememe Attention".
</ul>
</section>

<section>
<h2>Language Representation Learning</h2>
<ul>
	<li> <strong>CWE</strong>: Character Word Embeddings. [<a href=https://github.com/Leonard-Xu/CWE target=_blank>Git</a>] <br>
	This is the lab code of our IJCAI 2015 paper "Joint Learning of Character and Word Embeddings". This method is expected to learn Chinese word embeddings by taking those characters within words into consideration. The analogical reasoning dataset on Chinese is available in data folder.

	<li> <strong>CLWE</strong>: Cross-Lingual Word Embeddings. [<a href=src/acl2015_bilingual.html target=_blank>home</a>] <br>
	This is the lab code of our ACL 2015 short paper "Learning Cross-lingual Word Embeddings via Matrix Co-factorization". This method is expected to learn cross-lingual word embeddings with a matrix co-factorization framework.

	<li> <strong>OIWE</strong>: Online Interpretable Word Embeddings. [<a href=https://github.com/SkTim/OIWE target=_blank>Git</a>] <br>
	This is the lab code of our EMNLP 2015 short paper "Online Learning of Interpretable Word Embeddings". This method is expected to learn interpretable word embeddings based on OIWE-IPG model proposed in our paper.

	<li> <strong>TWE</strong>: Topical Word Embeddings. [<a href=https://github.com/thunlp/topical_word_embeddings target=_blank>Git</a>] <br>
	This is the lab code of our AAAI 2015 paper "Topical Word Embeddings". The method is expected to perform representation learning of words with their topic assignments by latent topic models such as Latent Dirichlet Allocation.
</ul>
</section>

<section>
<h2>General NLP</h2>
<ul>
	<li> <strong>THUCKE</strong>: An Open-Source Package for Chinese Keyphrase Extraction. [<a href=https://github.com/thunlp/THUCKE target=_blank>Git</a>]<br>
	The package can efficiently extract Chinese keyphrases by translating from documents to keyphrases, learned by word alignment models (WAM) that we propoased in [<a href=publications/emnlp2011.pdf target=_blank>EMNLP</a>][<a href=publications/conll2011.pdf target=_blank>CoNLL</a>].

	<li> <strong>TensorFlow-Summarization</strong>: An Open-Source Package for Neural Headline Generation. [<a href=https://github.com/thunlp/TensorFlow-Summarization target=_blank>Git</a>]<br>
	This is an implementation of sequence-to-sequence model using a bidirectional GRU encoder and a GRU decoder. This project aims to help people start working on Abstractive Short Text Summarization immediately. And hopefully, it may also work on machine translation tasks.

	<li> <strong>THUNSC</strong>: An Open-Source Package for Neural Sentiment Classification. [<a href=https://github.com/thunlp/NSC target=_blank>Git</a>]<br>
	Neural Sentiment Classification aims to classify the sentiment in a document with neural models, which has been the state-of-the-art methods for sentiment classification. In this package, we provide our implementations of NSC, NSC+LA and NSC+UPA [<a href=publications/emnlp2016.pdf target=_blank>Chen et al., 2016</a>] in which user and product information is considered via attentions over different semantic levels.

	<li> <strong>THUTAG</strong>: An Open-Source Package for Keyphrase Extraction and Social Tag Suggestion. [<a href=https://github.com/thunlp/THUTag target=_blank>Git</a>]<br>
	The package contains several keyphrase extraction methods including TextRank, ExpandRank, Topical PageRank and WAM, and social tag suggestion methods including KNN, PMI, TagLDA, TAM and WTM. The package has supported one of the most popular microblog apps, <a href=http://app.thunlp.org/weibo/>Weibo Keywords</a>, which has got more than 3.5 million registered users.

	<li> <strong>PLDA+</strong>: An Open-Source Package for Parallel LDA. [<a href=https://code.google.com/archive/p/plda/ target=_blank>Git</a>] <br>
	PLDA is a parallel C++ implementation of Latent Dirichlet Allocation (LDA). We present a highly optimized parallel implemention of the Gibbs sampling algorithm for the training/inference of LDA. The carefully designed architecture is expected to support extensions of this algorithm. PLDA+, an enhanced parallel implementation of LDA, can further improve scalability of LDA by signiﬁcantly reducing the unparallelizable communication bottleneck and achieve good load balancing.
</ul>
</section>

<section>
Last update: 22 Mar, 2018. 

<a href="http://www3.clustrmaps.com/counter/maps.php?url=http://nlp.csai.tsinghua.edu.cn/~lzy/" id="clustrMapsLink"><img src="http://www3.clustrmaps.com/counter/index2.php?url=http://nlp.csai.tsinghua.edu.cn/~lzy/" style="border:0px;" alt="Locations of visitors to this page" title="Locations of visitors to this page" id="clustrMapsImg" onerror="this.onerror=null; this.src='http://www2.clustrmaps.com/images/clustrmaps-back-soon.jpg'; document.getElementById('clustrMapsLink').href='http://www2.clustrmaps.com';" /></a>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?99c869e012bd35a145a383bbab6cca39";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

</section>
</body>
</html>
